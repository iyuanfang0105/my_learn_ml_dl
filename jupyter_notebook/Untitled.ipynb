{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# split the train and validataion dataset\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# normalization\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_valid = to_categorical(y_valid, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000, 28, 28), (6000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '6')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a smaple of train\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(x_train[1])\n",
    "plt.title(y_train[1].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/meizu/Work/py_env/my_tf_py3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/meizu/Work/py_env/my_tf_py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "inputShape=(28,28,1)\n",
    "input = Input(inputShape)\n",
    "\n",
    "x = Conv2D(64, (3,3), strides=(1,1), name='layer_conv1', padding='same')(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2), name='maxPool1')(x)\n",
    "\n",
    "x = Conv2D(64, (3,3), strides=(1,1), name='layer_conv2', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2), name='maxPool2')(x)\n",
    "\n",
    "x = Conv2D(32, (3,3),strides =(1,1), name='conv3', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D((2,2),name='maxPool3')(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation = 'relu', name='fc0')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(32, activation = 'relu', name='fc1')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(10, activation = 'softmax', name='fc2')(x)\n",
    "\n",
    "model = Model(inputs = input, outputs = x, name='Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "layer_conv1 (Conv2D)         (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "maxPool1 (MaxPooling2D)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "layer_conv2 (Conv2D)         (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "maxPool2 (MaxPooling2D)      (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 7, 7, 32)          18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "maxPool3 (MaxPooling2D)      (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 77,578\n",
      "Trainable params: 77,258\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_valid = x_valid.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54000, 28, 28, 1), (6000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally \n",
    "    height_shift_range=0.2,# randomly shift images vertically \n",
    "    horizontal_flip=True) # randomly flip images horizontally\n",
    "# fit augmented image generator on data\n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 4715s 87ms/step - loss: 0.1336 - acc: 0.9691 - val_loss: 0.1087 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "# trainning\n",
    "history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=32), \n",
    "                              validation_data=(x_valid, y_valid),\n",
    "                              steps_per_epoch=x_train.shape[0],\n",
    "                              epochs=1\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_tf_py3",
   "language": "python",
   "name": "my_tf_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
